{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import schedule\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the professors in the Imperial college as of 2020-07-29 02:09:47.220012\n",
      "['Dr Yves-Alexandre de Montjoye']\n",
      "['Dr Marc Deisenroth']\n",
      "['Dr Aldo Faisal']\n",
      "['Dr Arthur H C Gervais']\n",
      "['Prof. Yi-Ke Guo']\n",
      "['Dr Thomas Heinis']\n",
      "['Prof. William Knottenbelt']\n",
      "['Dr Peter McBrien']\n",
      "['Prof. Peter Pietzuch']\n",
      "['Dr Holger Pirk']\n",
      "Total number of professors: 10\n",
      "Content Type: <class 'bs4.element.ResultSet'>\n",
      "The keywords required gathered for all the professors:\n",
      "['Research interests', 'Data Privacy, Machine Learning for biometric and behavioral identification, Infrastructure for the safe and anonymous use of data, Data Science for Good.']\n",
      "['Research interests', 'Statistical Machine Learning, Robotics, Control, Time-Series Analysis, Signal Processing.']\n",
      "['Research interests', 'Neurotechnology, Biomedical Engineering, Machine Learning, Algorithmic Prediction of Human Behaviour.']\n",
      "['Research interests', 'My research focuses on the security, privacy and performance of blockchain technology. Because this technology is still in its infancy, I largely focus on understanding and quantifying the tension points and tradeoffs in terms of security, privacy and performance, with the goal to build a mainstream, scalable, open, an...']\n",
      "['Research interests', 'Knowledge Discovery, Data Mining and Large-Scale Data Management.']\n",
      "['Research interests', 'Scientific Data Management, Distributed Data Processing, Spatial Databases, Indexing.']\n",
      "['Research interests', 'Application of mathematical modelling techniques to real life systems. modelling and optimisation in parallel queueing systems (especially split-merge and\\xa0']\n",
      "['Research interests', 'Data Integration, Information Systems Modelling and Distributed Databases']\n",
      "['Research interests', 'Distributed Systems, Systems and Data Management and the\\xa0Design and Engineering of Scalable, and Reliable and Secure Large-Scale Software Systems.']\n",
      "['Research interests', 'My research interests lie in analytical query processing on memory-resident data. In particular, I study storage schemes and processing models for modern hardware.']\n",
      "The Keywords length: 10\n",
      "['http://demontjoye.com/index.html', 'https://sites.google.com/view/marcdeisenroth', 'http://www.imperial.ac.uk/people/a.faisal', 'http://arthurgervais.com/', 'http://www.imperial.ac.uk/people/y.guo', 'http://wp.doc.ic.ac.uk/theinis/', 'https://www.doc.ic.ac.uk/~wjk/', 'https://www.doc.ic.ac.uk/~pjm/', 'https://www.doc.ic.ac.uk/~prp/', 'https://www.doc.ic.ac.uk/~hlgr/']\n",
      "                          0\n",
      "0  Imperial College London \n",
      "1  Imperial College London \n",
      "2  Imperial College London \n",
      "3  Imperial College London \n",
      "4  Imperial College London \n",
      "5  Imperial College London \n",
      "6  Imperial College London \n",
      "7  Imperial College London \n",
      "8  Imperial College London \n",
      "9  Imperial College London \n",
      "                            Name  \\\n",
      "0  Dr Yves-Alexandre de Montjoye   \n",
      "1             Dr Marc Deisenroth   \n",
      "2                 Dr Aldo Faisal   \n",
      "3          Dr Arthur H C Gervais   \n",
      "4                Prof. Yi-Ke Guo   \n",
      "5               Dr Thomas Heinis   \n",
      "6      Prof. William Knottenbelt   \n",
      "7               Dr Peter McBrien   \n",
      "8           Prof. Peter Pietzuch   \n",
      "9                 Dr Holger Pirk   \n",
      "\n",
      "                                           Expertise  \\\n",
      "0  Research interestsData Privacy, Machine Learni...   \n",
      "1  Research interestsStatistical Machine Learning...   \n",
      "2  Research interestsNeurotechnology, Biomedical ...   \n",
      "3  Research interestsMy research focuses on the s...   \n",
      "4  Research interestsKnowledge Discovery, Data Mi...   \n",
      "5  Research interestsScientific Data Management, ...   \n",
      "6  Research interestsApplication of mathematical ...   \n",
      "7  Research interestsData Integration, Informatio...   \n",
      "8  Research interestsDistributed Systems, Systems...   \n",
      "9  Research interestsMy research interests lie in...   \n",
      "\n",
      "                                 Email  \\\n",
      "0     mailto:demontjoye@imperial.ac.uk   \n",
      "1   mailto:m.deisenroth@imperial.ac.uk   \n",
      "2       mailto:a.faisal@imperial.ac.uk   \n",
      "3      mailto:a.gervais@imperial.ac.uk   \n",
      "4          mailto:y.guo@imperial.ac.uk   \n",
      "5       mailto:t.heinis@imperial.ac.uk   \n",
      "6  mailto:w.knottenbelt@imperial.ac.uk   \n",
      "7      mailto:p.mcbrien@imperial.ac.uk   \n",
      "8            mailto:prp@imperial.ac.uk   \n",
      "9           mailto:pirk@imperial.ac.uk   \n",
      "\n",
      "                                           Link           University_Name  \n",
      "0              http://demontjoye.com/index.html  Imperial College London   \n",
      "1  https://sites.google.com/view/marcdeisenroth  Imperial College London   \n",
      "2     http://www.imperial.ac.uk/people/a.faisal  Imperial College London   \n",
      "3                     http://arthurgervais.com/  Imperial College London   \n",
      "4        http://www.imperial.ac.uk/people/y.guo  Imperial College London   \n",
      "5               http://wp.doc.ic.ac.uk/theinis/  Imperial College London   \n",
      "6                https://www.doc.ic.ac.uk/~wjk/  Imperial College London   \n",
      "7                https://www.doc.ic.ac.uk/~pjm/  Imperial College London   \n",
      "8                https://www.doc.ic.ac.uk/~prp/  Imperial College London   \n",
      "9               https://www.doc.ic.ac.uk/~hlgr/  Imperial College London   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Every 1 week do primary() (last run: [never], next run: 2020-08-05 02:09:49)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def primary():\n",
    "    %run \"Imperial.ipynb\"\n",
    "primary()\n",
    "schedule.every(1).week.do(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John Carroll']\n",
      "['Bill Keller']\n",
      "['Novi Quadrianto']\n",
      "['Julie Weeds']\n",
      "['David Weir']\n",
      "['Computational Linguistics, Computational/Corpus Linguistics, Machine Learning (AI), Medical Informatics, Natural Language Processing']\n",
      "['Computational Linguistics, Computational/Corpus Linguistics, Linguistics, Machine Learning (AI), Natural Language Processing, Probabilistic Methods, Semantics And Pragmatics']\n",
      "['Bayesian Methods, Computer Vision - Machine Learning, Kernel Methods, Machine Learning (AI), Optimisation (AI), Probabilistic Methods, Time Series']\n",
      "['Applied machine learning,\\xa0Computational Linguistics,\\xa0Computational/Corpus Linguistics,\\xa0Data Science,\\xa0Natural Language Processing,\\xa0Semantics And Pragmatics']\n",
      "['Computational Linguistics, Linguistics, Natural Language Processing']\n",
      "['J.A.Carroll@sussex.ac.uk']\n",
      "['billk@sussex.ac.uk']\n",
      "['N.Quadrianto@sussex.ac.uk']\n",
      "['juliewe@sussex.ac.uk']\n",
      "['D.J.Weir@sussex.ac.uk']\n",
      "              Name                                          Expertise  \\\n",
      "0     John Carroll  Computational Linguistics, Computational/Corpu...   \n",
      "1      Bill Keller  Computational Linguistics, Computational/Corpu...   \n",
      "2  Novi Quadrianto  Bayesian Methods, Computer Vision - Machine Le...   \n",
      "3      Julie Weeds  Applied machine learning,Â Computational Lingui...   \n",
      "4       David Weir  Computational Linguistics, Linguistics, Natura...   \n",
      "\n",
      "                       Email  \\\n",
      "0   J.A.Carroll@sussex.ac.uk   \n",
      "1         billk@sussex.ac.uk   \n",
      "2  N.Quadrianto@sussex.ac.uk   \n",
      "3       juliewe@sussex.ac.uk   \n",
      "4      D.J.Weir@sussex.ac.uk   \n",
      "\n",
      "                                                Link       University_Name  \n",
      "0  https://www.sussex.ac.uk/informatics/people/pe...  University of Sussex  \n",
      "1  https://www.sussex.ac.uk/informatics/people/pe...  University of Sussex  \n",
      "2  https://www.sussex.ac.uk/informatics/people/pe...  University of Sussex  \n",
      "3  https://www.sussex.ac.uk/informatics/people/pe...  University of Sussex  \n",
      "4  https://www.sussex.ac.uk/informatics/people/pe...  University of Sussex  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Every 1 week do primary() (last run: [never], next run: 2020-08-05 02:09:53)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def primary():\n",
    "    %run \"sussex.ipynb\"\n",
    "primary()\n",
    "schedule.every(1).week.do(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gnani/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/gnani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/gnani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gnani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing ntlk packages\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Name', 'Expertise', 'Email', 'Link', 'University_Name'], dtype='object')\n",
      "search for:machine\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Expertise</th>\n",
       "      <th>Email</th>\n",
       "      <th>Link</th>\n",
       "      <th>University_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>John Carroll</td>\n",
       "      <td>computational linguistics computational corpus...</td>\n",
       "      <td>J.A.Carroll@sussex.ac.uk</td>\n",
       "      <td>https://www.sussex.ac.uk/informatics/people/pe...</td>\n",
       "      <td>University of Sussex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bill Keller</td>\n",
       "      <td>computational linguistics computational corpus...</td>\n",
       "      <td>billk@sussex.ac.uk</td>\n",
       "      <td>https://www.sussex.ac.uk/informatics/people/pe...</td>\n",
       "      <td>University of Sussex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Novi Quadrianto</td>\n",
       "      <td>bayesian method computer vision machine learn ...</td>\n",
       "      <td>N.Quadrianto@sussex.ac.uk</td>\n",
       "      <td>https://www.sussex.ac.uk/informatics/people/pe...</td>\n",
       "      <td>University of Sussex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Julie Weeds</td>\n",
       "      <td>apply machine learn computational linguistics ...</td>\n",
       "      <td>juliewe@sussex.ac.uk</td>\n",
       "      <td>https://www.sussex.ac.uk/informatics/people/pe...</td>\n",
       "      <td>University of Sussex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Dr Yves-Alexandre de Montjoye</td>\n",
       "      <td>research interestsdata privacy machine learn b...</td>\n",
       "      <td>mailto:demontjoye@imperial.ac.uk</td>\n",
       "      <td>http://demontjoye.com/index.html</td>\n",
       "      <td>Imperial College London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Dr Marc Deisenroth</td>\n",
       "      <td>research interestsstatistical machine learn ro...</td>\n",
       "      <td>mailto:m.deisenroth@imperial.ac.uk</td>\n",
       "      <td>https://sites.google.com/view/marcdeisenroth</td>\n",
       "      <td>Imperial College London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr Aldo Faisal</td>\n",
       "      <td>research interestsneurotechnology biomedical e...</td>\n",
       "      <td>mailto:a.faisal@imperial.ac.uk</td>\n",
       "      <td>http://www.imperial.ac.uk/people/a.faisal</td>\n",
       "      <td>Imperial College London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Dr Arthur H C Gervais</td>\n",
       "      <td>research interestsmy research focus security p...</td>\n",
       "      <td>mailto:a.gervais@imperial.ac.uk</td>\n",
       "      <td>http://arthurgervais.com/</td>\n",
       "      <td>Imperial College London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                           Name  \\\n",
       "0   0                   John Carroll   \n",
       "1   1                    Bill Keller   \n",
       "2   2                Novi Quadrianto   \n",
       "3   3                    Julie Weeds   \n",
       "5   0  Dr Yves-Alexandre de Montjoye   \n",
       "6   1             Dr Marc Deisenroth   \n",
       "7   2                 Dr Aldo Faisal   \n",
       "8   3          Dr Arthur H C Gervais   \n",
       "\n",
       "                                           Expertise  \\\n",
       "0  computational linguistics computational corpus...   \n",
       "1  computational linguistics computational corpus...   \n",
       "2  bayesian method computer vision machine learn ...   \n",
       "3  apply machine learn computational linguistics ...   \n",
       "5  research interestsdata privacy machine learn b...   \n",
       "6  research interestsstatistical machine learn ro...   \n",
       "7  research interestsneurotechnology biomedical e...   \n",
       "8  research interestsmy research focus security p...   \n",
       "\n",
       "                                Email  \\\n",
       "0            J.A.Carroll@sussex.ac.uk   \n",
       "1                  billk@sussex.ac.uk   \n",
       "2           N.Quadrianto@sussex.ac.uk   \n",
       "3                juliewe@sussex.ac.uk   \n",
       "5    mailto:demontjoye@imperial.ac.uk   \n",
       "6  mailto:m.deisenroth@imperial.ac.uk   \n",
       "7      mailto:a.faisal@imperial.ac.uk   \n",
       "8     mailto:a.gervais@imperial.ac.uk   \n",
       "\n",
       "                                                Link           University_Name  \n",
       "0  https://www.sussex.ac.uk/informatics/people/pe...      University of Sussex  \n",
       "1  https://www.sussex.ac.uk/informatics/people/pe...      University of Sussex  \n",
       "2  https://www.sussex.ac.uk/informatics/people/pe...      University of Sussex  \n",
       "3  https://www.sussex.ac.uk/informatics/people/pe...      University of Sussex  \n",
       "5                   http://demontjoye.com/index.html  Imperial College London   \n",
       "6       https://sites.google.com/view/marcdeisenroth  Imperial College London   \n",
       "7          http://www.imperial.ac.uk/people/a.faisal  Imperial College London   \n",
       "8                          http://arthurgervais.com/  Imperial College London   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Every 1 week do primary() (last run: [never], next run: 2020-08-05 02:11:04)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def info_ret():\n",
    "    raw_df = pd.read_csv('/Users/gnani/Documents/Candy 3 univ assignments/Sussex.csv')\n",
    "    raw_df.rename( columns={'Unnamed: 0':'ID'}, inplace=True )\n",
    "    raw_df2 = pd.read_csv('/Users/gnani/Documents/Candy 3 univ assignments/Imperial.csv')\n",
    "    raw_df2.rename( columns={'Unnamed: 0':'ID'}, inplace=True )\n",
    "    df = pd.concat([raw_df, raw_df2], ignore_index=True)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    def poslemma(pos_tag):\n",
    "        word, pos = pos_tag\n",
    "        if pos.startswith('R'):\n",
    "            pos = 'r'\n",
    "        elif pos.startswith('V'):\n",
    "            pos = 'v'\n",
    "        elif pos.startswith('J'):\n",
    "            pos ='a'\n",
    "        else:\n",
    "            pos ='n'\n",
    "\n",
    "        return wnl.lemmatize(word,pos=pos)\n",
    "\n",
    "    def lematization(sent):\n",
    "        tokens = sent.split()\n",
    "        pos = pos_tag(tokens)\n",
    "        return \" \".join([poslemma(tag) for tag in pos])\n",
    "    from nltk.corpus import stopwords\n",
    "    stop = stopwords.words('english')\n",
    "    def tokenization(Expertise):\n",
    "        Expertise = Expertise.split()\n",
    "        Expertise_list = [word for word in Expertise if word not in stop]\n",
    "        return \" \".join(Expertise_list)\n",
    "    def textprocessing(sample):\n",
    "        sample = sample.lower()\n",
    "        sample = re.sub(r'[^a-z0-9]',\" \",sample)\n",
    "        sample = tokenization(sample)\n",
    "        sample = lematization(sample)\n",
    "        return sample\n",
    "    df['Expertise'] = df['Expertise'].apply(textprocessing)\n",
    "    def textprocess(Expertise):\n",
    "        # lower case\n",
    "        try:\n",
    "            Expertise = Expertise.lower()\n",
    "            # Remove special characters and numbers\n",
    "            Expertise = re.sub(r'[^a-z ]','',Expertise)\n",
    "            return Expertise\n",
    "        except:\n",
    "            pass\n",
    "    def process_string(text):\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('','',string.punctuation))\n",
    "        return text\n",
    "    df['Expertise']= df['Expertise'].apply(textprocess)\n",
    "    sample = df.loc[0,:].copy()\n",
    "    def post_df(df):\n",
    "        df = df\n",
    "        df['Expertise'] = df['Expertise'].apply(process_string)\n",
    "        df['text'] = df['Expertise']\n",
    "        drop_cols = ['Name','Expertise','Email','Link','University_Name']\n",
    "        df = df.drop(drop_cols, axis=1)\n",
    "        return df\n",
    "    def build_pos(df,pos):\n",
    "        to_add = post_df(df)\n",
    "        pos = pos_all(df=to_add,pos = pos)\n",
    "        return pos\n",
    "    ID = sample.ID\n",
    "    pos_test={}\n",
    "    multiple = sample.Expertise.split(\" \")\n",
    "    word=multiple[0]\n",
    "    sample={word: [ID]}\n",
    "    for word in multiple:\n",
    "        if word in pos_test.keys():\n",
    "            if ID not in pos_test[word]:\n",
    "                pos_test[word].append(ID)\n",
    "        else:\n",
    "            pos_test[word]=[ID]\n",
    "            \n",
    "    def pos_it(sample, pos):\n",
    "        multiple = sample.text.split(\" \")\n",
    "        ID = sample.ID\n",
    "        for word in multiple:\n",
    "            if word in pos_test.keys():\n",
    "                if ID not in pos_test[word]:\n",
    "                    pos_test[word].append(ID)\n",
    "            else:\n",
    "                pos_test[word]=[ID]\n",
    "        return pos_test\n",
    "    def pos_all(df, pos):\n",
    "        for i in range(len(df)):\n",
    "            sample=df.loc[i, :]\n",
    "            pos=pos_it(sample,pos)\n",
    "        return pos\n",
    "    \n",
    "    pos = build_pos(df,pos={})\n",
    "    df.drop([\"text\"], axis = 1, inplace = True) \n",
    "    print(df.columns)\n",
    "    key_pos = pos\n",
    "    query_processing = input('search for:')\n",
    "    query_processing = process_string(query_processing)\n",
    "    retrieved = key_pos[query_processing]\n",
    "    display(df[df['ID'].isin(retrieved)])\n",
    "    \n",
    "    \n",
    "    \n",
    "info_ret()\n",
    "schedule.every(1).week.do(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":(\n"
     ]
    }
   ],
   "source": [
    "print(\":(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
